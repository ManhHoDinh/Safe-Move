{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n\n# How to Train YOLOv10 Object Detection on a Custom Dataset\n\n---\n\n[![arXiv](https://img.shields.io/badge/arXiv-2405.14458-b31b1b.svg)](https://arxiv.org/pdf/2405.14458.pdf)\n[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/THU-MIG/yolov10)\n[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/SkalskiP/YOLO-ARENA)\n\nYOLOv10 is a new generation in the YOLO series for real-time end-to-end object detection. It aims to improve both the performance and efficiency of YOLOs by eliminating the need for non-maximum suppression (NMS) and optimizing model architecture comprehensively. This advancement reduces computational overhead, enhancing both efficiency and capability. YOLOv10 shows state-of-the-art performance and efficiency, with YOLOv10-S being 1.8 times faster than RT-DETR-R18 and having significantly fewer parameters and FLOPs. Additionally, YOLOv10-B demonstrates 46% less latency and 25% fewer parameters compared to YOLOv9-C while maintaining the same performance.\n\n<p align=\"center\">\n  <img src=\"https://storage.googleapis.com/com-roboflow-marketing/notebooks/examples/yolov10_latency.svg\" width=48%>\n  <img src=\"https://storage.googleapis.com/com-roboflow-marketing/notebooks/examples/yolov10_params.svg\" width=48%> <br>\n  Comparisons with others in terms of latency-accuracy (left) and size-accuracy (right) trade-offs.\n</p>\n\n## Pro Tip: Use GPU Acceleration\n\nIf you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.\n\n## Steps in this Tutorial\n\nIn this tutorial, we are going to cover:\n\n- Before you start\n- Install YOLOv10\n- Download pre-trained weights\n- Download example data\n- Inference with Pre-trained COCO Model\n- Download dataset from Roboflow Universe\n- Custom Training\n- Validate Custom Model\n- Inference with Custom Model\n\n**Let's begin!**","metadata":{"id":"oe9vkEvFABbN"}},{"cell_type":"markdown","source":"## Before you start\n\nLet's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`.","metadata":{"id":"FyRdDYkqAKN4"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"Y8cDtxLIBHgQ","outputId":"5c9cdd0e-df99-48c1-c519-c2e7a5862a3c","execution":{"iopub.status.busy":"2024-06-18T06:06:36.113429Z","iopub.execute_input":"2024-06-18T06:06:36.114266Z","iopub.status.idle":"2024-06-18T06:06:37.101154Z","shell.execute_reply.started":"2024-06-18T06:06:36.114231Z","shell.execute_reply":"2024-06-18T06:06:37.100272Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"id":"CjpPg4mGKc1v","outputId":"0c02389f-cdc9-45e5-b0f0-5ea7d30d6c32","execution":{"iopub.status.busy":"2024-06-18T06:06:37.103076Z","iopub.execute_input":"2024-06-18T06:06:37.103373Z","iopub.status.idle":"2024-06-18T06:06:37.10846Z","shell.execute_reply.started":"2024-06-18T06:06:37.103346Z","shell.execute_reply":"2024-06-18T06:06:37.1075Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q roboflow\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"tOpspuWdrpKXWXBq36Lm\")\nproject = rf.workspace(\"uit-2pejh\").project(\"flooded_visdrone\")\nversion = project.version(1)\nmodel_format = 'yolov8'\ndataset = version.download(model_format)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:06:37.109659Z","iopub.execute_input":"2024-06-18T06:06:37.10995Z","iopub.status.idle":"2024-06-18T06:06:55.895864Z","shell.execute_reply.started":"2024-06-18T06:06:37.109919Z","shell.execute_reply":"2024-06-18T06:06:55.894924Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!sed -i '$d' {dataset.location}/data.yaml\n!sed -i '$d' {dataset.location}/data.yaml\n!sed -i '$d' {dataset.location}/data.yaml\n!sed -i '$d' {dataset.location}/data.yaml\n!echo -e \"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\" >> {dataset.location}/data.yaml","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:06:55.898027Z","iopub.execute_input":"2024-06-18T06:06:55.898338Z","iopub.status.idle":"2024-06-18T06:07:00.635142Z","shell.execute_reply.started":"2024-06-18T06:06:55.898311Z","shell.execute_reply":"2024-06-18T06:07:00.633971Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Install YOLOv10","metadata":{"id":"3C3EO_2zNChu"}},{"cell_type":"markdown","source":"**NOTE:** Currently, YOLOv10 does not have its own PyPI package. Therefore, we need to install the code from the source.","metadata":{"id":"eBrlDQHUo_M5"}},{"cell_type":"code","source":"!pip install -q git+https://github.com/THU-MIG/yolov10.git","metadata":{"id":"tdSMcABDNKW-","outputId":"66a06e7b-ab7b-4342-aa39-ec70cfac22b8","execution":{"iopub.status.busy":"2024-06-18T06:07:00.636669Z","iopub.execute_input":"2024-06-18T06:07:00.637073Z","iopub.status.idle":"2024-06-18T06:07:29.739767Z","shell.execute_reply.started":"2024-06-18T06:07:00.637014Z","shell.execute_reply":"2024-06-18T06:07:29.738487Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**NOTE:** We will also install two additional packages: [`roboflow`](https://github.com/roboflow/roboflow-python) to download the dataset from [Roboflow Universe](https://universe.roboflow.com/), which we will use to train our model, and [`supervision`](https://github.com/roboflow/supervision), which we will use for visualizing the results.","metadata":{"id":"Szn2UQBxqxnR"}},{"cell_type":"code","source":"!pip install -q supervision","metadata":{"id":"Bf6A7E9glExI","outputId":"38a8229d-86d2-47de-c065-7c82457835e4","execution":{"iopub.status.busy":"2024-06-18T06:07:29.741551Z","iopub.execute_input":"2024-06-18T06:07:29.741959Z","iopub.status.idle":"2024-06-18T06:07:42.492803Z","shell.execute_reply.started":"2024-06-18T06:07:29.741922Z","shell.execute_reply":"2024-06-18T06:07:42.491579Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Download pre-trained weights","metadata":{"id":"JMEtcxdshoEC"}},{"cell_type":"markdown","source":"**NOTE:** YOLOv10 provides weight files pre-trained on the COCO dataset in various sizes. Let's download them.","metadata":{"id":"CF1nAW3Dri83"}},{"cell_type":"code","source":"!rm -r {HOME}/weights/\n!mkdir -p {HOME}/weights\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10n.pt\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10s.pt\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10m.pt\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10b.pt\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10x.pt\n!wget -P {HOME}/weights -q https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10l.pt\n!ls -lh {HOME}/weights","metadata":{"id":"2l67kw8xiYPX","outputId":"31d0dff4-c142-4ba8-fd19-46a8e5935067","execution":{"iopub.status.busy":"2024-06-18T06:07:42.494497Z","iopub.execute_input":"2024-06-18T06:07:42.49534Z","iopub.status.idle":"2024-06-18T06:08:00.412378Z","shell.execute_reply.started":"2024-06-18T06:07:42.495302Z","shell.execute_reply":"2024-06-18T06:08:00.41126Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Download example data\n\n**NONE:** Let's download few example images. Feel free to use your images or videos.","metadata":{"id":"QGXXr46SlXrr"}},{"cell_type":"code","source":"!mkdir -p {HOME}/data\n!wget -P {HOME}/data -q https://media.roboflow.com/notebooks/examples/dog.jpeg\n!ls -lh {HOME}/data","metadata":{"id":"HzN8FRtSlemo","outputId":"ed913dd8-7f6c-4157-ec1d-6e69eb6d18d0","execution":{"iopub.status.busy":"2024-06-18T06:08:00.413806Z","iopub.execute_input":"2024-06-18T06:08:00.414138Z","iopub.status.idle":"2024-06-18T06:08:03.663216Z","shell.execute_reply.started":"2024-06-18T06:08:00.414109Z","shell.execute_reply":"2024-06-18T06:08:03.662273Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference with Pre-trained COCO Model","metadata":{"id":"s5RGYA6sPgEd"}},{"cell_type":"markdown","source":"**NOTE:** YOLOv10 is based on YOLOv8, and like YOLOv8, it can be used in both CLI and SDK modes.","metadata":{"id":"i4Z0cZapszEY"}},{"cell_type":"markdown","source":"### ðŸ’» CLI","metadata":{"id":"fT1qD4toTTw0"}},{"cell_type":"code","source":"%cd {HOME}\n\n!yolo task=detect mode=predict conf=0.25 save=True \\\nmodel={HOME}/weights/yolov10n.pt \\\nsource={HOME}/data/dog.jpeg","metadata":{"id":"FDbMt_M6PiXb","outputId":"c13a65b1-3a23-44fc-9f9d-5e9ab152f4fa","execution":{"iopub.status.busy":"2024-06-18T06:08:03.664579Z","iopub.execute_input":"2024-06-18T06:08:03.664847Z","iopub.status.idle":"2024-06-18T06:08:18.320695Z","shell.execute_reply.started":"2024-06-18T06:08:03.664823Z","shell.execute_reply":"2024-06-18T06:08:18.319739Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**NONE:** Let's display result.","metadata":{"id":"ZN9CdBZ2nYRf"}},{"cell_type":"code","source":"%cd {HOME}\n\nfrom IPython.display import Image\n\nImage(filename='runs/detect/predict/dog.jpeg', height=600)","metadata":{"id":"LyopYpK1TQrB","outputId":"29c01ac5-9290-4408-a595-830a9c1d718a","execution":{"iopub.status.busy":"2024-06-18T06:08:18.32501Z","iopub.execute_input":"2024-06-18T06:08:18.325739Z","iopub.status.idle":"2024-06-18T06:08:18.353601Z","shell.execute_reply.started":"2024-06-18T06:08:18.325708Z","shell.execute_reply":"2024-06-18T06:08:18.35272Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ðŸ Python SDK","metadata":{"id":"AFMBYQtMVL-B"}},{"cell_type":"code","source":"from ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/weights/yolov10n.pt')\nresults = model(source=f'{HOME}/data/dog.jpeg', conf=0.25)","metadata":{"id":"Rx9NWF-sVN6Y","outputId":"10048c63-028f-437c-b471-862ab42f705e","execution":{"iopub.status.busy":"2024-06-18T06:08:18.354666Z","iopub.execute_input":"2024-06-18T06:08:18.354903Z","iopub.status.idle":"2024-06-18T06:08:22.530207Z","shell.execute_reply.started":"2024-06-18T06:08:18.354883Z","shell.execute_reply":"2024-06-18T06:08:22.529235Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results[0].boxes.xyxy","metadata":{"id":"kAi4PvrItTCf","outputId":"14af63c2-d24c-4a35-e9e0-a39b185c3f0c","execution":{"iopub.status.busy":"2024-06-18T06:08:22.531323Z","iopub.execute_input":"2024-06-18T06:08:22.531737Z","iopub.status.idle":"2024-06-18T06:08:22.606624Z","shell.execute_reply.started":"2024-06-18T06:08:22.531712Z","shell.execute_reply":"2024-06-18T06:08:22.605697Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results[0].boxes.conf","metadata":{"id":"HqT2M01K1LUb","outputId":"ca8cbf33-7024-4bb1-c12c-904115fde2ef","execution":{"iopub.status.busy":"2024-06-18T06:08:22.607649Z","iopub.execute_input":"2024-06-18T06:08:22.607905Z","iopub.status.idle":"2024-06-18T06:08:22.615321Z","shell.execute_reply.started":"2024-06-18T06:08:22.607883Z","shell.execute_reply":"2024-06-18T06:08:22.614381Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results[0].boxes.cls","metadata":{"id":"gKIwJ5yw1PMb","outputId":"a39e7a50-e37a-451f-8999-f0cb9766030f","execution":{"iopub.status.busy":"2024-06-18T06:08:22.616294Z","iopub.execute_input":"2024-06-18T06:08:22.616557Z","iopub.status.idle":"2024-06-18T06:08:22.623855Z","shell.execute_reply.started":"2024-06-18T06:08:22.616534Z","shell.execute_reply":"2024-06-18T06:08:22.623071Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**NONE:** Let's display result using `supervision`.","metadata":{"id":"O26ZKAsindq8"}},{"cell_type":"code","source":"import cv2\nimport supervision as sv\nfrom ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/weights/yolov10n.pt')\nimage = cv2.imread(f'{HOME}/data/dog.jpeg')\nresults = model(image)[0]\ndetections = sv.Detections.from_ultralytics(results)\n\nbounding_box_annotator = sv.BoundingBoxAnnotator()\nlabel_annotator = sv.LabelAnnotator()\n\nannotated_image = bounding_box_annotator.annotate(\n    scene=image, detections=detections)\nannotated_image = label_annotator.annotate(\n    scene=annotated_image, detections=detections)\n\nsv.plot_image(annotated_image)","metadata":{"id":"SaKTSzSWnG7s","outputId":"f0f21cda-95bc-401c-983e-3473b88c331d","execution":{"iopub.status.busy":"2024-06-18T06:08:22.625355Z","iopub.execute_input":"2024-06-18T06:08:22.625688Z","iopub.status.idle":"2024-06-18T06:08:23.631726Z","shell.execute_reply.started":"2024-06-18T06:08:22.625657Z","shell.execute_reply":"2024-06-18T06:08:23.630761Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Download dataset from Roboflow Universe","metadata":{"id":"t8Epf5rhnpV_"}},{"cell_type":"code","source":"!zip -r train_yolov10.zip runs/detect/train11/","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:15:39.009883Z","iopub.execute_input":"2024-06-23T08:15:39.010307Z","iopub.status.idle":"2024-06-23T08:15:59.729105Z","shell.execute_reply.started":"2024-06-23T08:15:39.010272Z","shell.execute_reply":"2024-06-23T08:15:59.728203Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mv train_yolov10.zip /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:18:10.534481Z","iopub.execute_input":"2024-06-23T08:18:10.534866Z","iopub.status.idle":"2024-06-23T08:18:11.53404Z","shell.execute_reply.started":"2024-06-23T08:18:10.534826Z","shell.execute_reply":"2024-06-23T08:18:11.532884Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\nos.environ[\"WANDB_MODE\"] = \"dryrun\"\n\n%cd {HOME}\n\n# Check if multiple GPUs are available\nif torch.cuda.device_count() > 1:\n  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n  # This makes the model utilize multiple GPUs\n  model = torch.nn.DataParallel(model)\n\n!yolo task=detect mode=train epochs=100 batch=16 plots=True \\\nmodel={HOME}/weights/yolov10m.pt \\\ndata={dataset.location}/data.yaml","metadata":{"id":"BSd93ZJzZZKt","outputId":"75559c0d-7b47-45a7-9121-7cd2b5af9044","execution":{"iopub.status.busy":"2024-06-18T06:08:23.633202Z","iopub.execute_input":"2024-06-18T06:08:23.633529Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom Training","metadata":{"id":"YUjFBKKqXa-u"}},{"cell_type":"code","source":"!ls {HOME}/runs/detect/train3/","metadata":{"id":"1MScstfHhArr","outputId":"68bc26e2-178a-407e-c18a-8466fbb8cca6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train3/confusion_matrix.png', width=600)","metadata":{"id":"_J35i8Ofhjxa","outputId":"cf66f4e6-4e0d-49dc-9254-b1b496e83d7e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train3/results.png', width=600)","metadata":{"id":"A-urTWUkhRmn","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference with Custom Model","metadata":{"id":"Sh6h0MOEy2WX"}},{"cell_type":"markdown","source":"**NOTE:** Let's start by loading our newly trained model.","metadata":{"id":"TNjsAO8m08ti"}},{"cell_type":"code","source":"from ultralytics import YOLOv10\n\nmodel = YOLOv10(f'{HOME}/runs/detect/train/weights/best.pt')\n\ndataset = sv.DetectionDataset.from_yolo(\n    images_directory_path=f\"{dataset.location}/valid/images\",\n    annotations_directory_path=f\"{dataset.location}/valid/labels\",\n    data_yaml_path=f\"{dataset.location}/data.yaml\"\n)\n\nbounding_box_annotator = sv.BoundingBoxAnnotator()\nlabel_annotator = sv.LabelAnnotator()","metadata":{"id":"AY1ajwSzyXCE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**NOTE:** Let's randomly select an image from our validation set and visualize the results.","metadata":{"id":"ibNL8dwU1Jqw"}},{"cell_type":"code","source":"import random\n\nrandom_image = random.choice(list(dataset.images.keys()))\nrandom_image = dataset.images[random_image]\n\nresults = model(source=random_image, conf=0.25)[0]\ndetections = sv.Detections.from_ultralytics(results)\n\nannotated_image = bounding_box_annotator.annotate(\n    scene=random_image, detections=detections)\nannotated_image = label_annotator.annotate(\n    scene=annotated_image, detections=detections)\n\nsv.plot_image(annotated_image)","metadata":{"id":"rDuvNsnH0OEV","trusted":true},"outputs":[],"execution_count":null}]}